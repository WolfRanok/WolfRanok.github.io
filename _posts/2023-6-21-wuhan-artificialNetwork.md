---
layout: post
title: 神经网络
author: Ranok
tags: [python, 人工智能, 期末考试]     #标签会影响
feature-img: "assets/img/feature-img/artificialNetwork.jpg" # 这是一个会出现在博客文章内部的图片
thumbnail: "assets/img/thumbnails/feature-img/artificialNetwork.jpg" # 这是一个会出现在博客外部的图片
permalink: artificialNetwork # 这条会将该界面的URL自定义
---

&emsp;&emsp;人工神经网络（Artificial Neural Networks，简写为ANNs）也简称为神经网络（NNs）或称作连接模型（Connection Model），它是一种模仿动物神经网络行为特征，进行分布式并行信息处理的算法数学模型。这种网络依靠系统的复杂程度，通过调整内部大量节点之间相互连接的关系，从而达到处理信息的目的。

---

# 前言
&emsp;&emsp;本博客针对神经网络期末考试课程整理，由于该授课老师对考试内容透露较少，因此整理的内容不一定能准确的压到，请做好心理准备。

---

# 目录
- [前言](#前言)
- [目录](#目录)
- [正文](#正文)
	- [问答题](#问答题)
		- [1 神经网络的优化方案（5条）](#1-神经网络的优化方案5条)
		- [2 过拟合的优化方案（5条）](#2-过拟合的优化方案5条)
		- [3 对公式中的参数解释](#3-对公式中的参数解释)
		- [4（必考）列举深度学习中最常见的激活函数并说明（3条）](#4必考列举深度学习中最常见的激活函数并说明3条)
		- [5 CNN的基本结构，有哪些基本模块和功能](#5-cnn的基本结构有哪些基本模块和功能)
		- [6 卷积神经网络相关问题](#6-卷积神经网络相关问题)
			- [6.1 卷积神经网络主要工作是什么？](#61-卷积神经网络主要工作是什么)
			- [6.2 池化层的池化作用](#62-池化层的池化作用)
			- [6.3简述两种池化方式](#63简述两种池化方式)
		- [7 对一些名词的解释](#7-对一些名词的解释)
			- [Epoch](#epoch)
			- [Batch](#batch)
			- [interation](#interation)
	- [编程题](#编程题)
		- [A卷](#a卷)
			- [1 导入tensorflow模块并命名为tf](#1-导入tensorflow模块并命名为tf)
			- [2 利用constent创建一个形状为2\*2，数值分别为\[1,2,3,4\]，类型为float的常量tensor\_a](#2-利用constent创建一个形状为22数值分别为1234类型为float的常量tensor_a)
			- [3 创建一个形状为2\*2的变量tensor\_b，并且b中的每个元素的值为1](#3-创建一个形状为22的变量tensor_b并且b中的每个元素的值为1)
			- [4 将两个tensor\_a和tensor\_b相加，定义为tensor\_c](#4-将两个tensor_a和tensor_b相加定义为tensor_c)
			- [5 tensor\_c的数值是多少](#5-tensor_c的数值是多少)
		- [B卷](#b卷)
			- [1 导入tensorflow模块并命名为tf](#1-导入tensorflow模块并命名为tf-1)
			- [2 利用constent创建一个形状为3\*2，数值分别为\[1,2,3,4,5,6\]，类型为float的常量tensor\_a](#2-利用constent创建一个形状为32数值分别为123456类型为float的常量tensor_a)
			- [3 创建一个形状为2\*2的变量tensor\_b，并且b中的每个元素的值为1](#3-创建一个形状为22的变量tensor_b并且b中的每个元素的值为1-1)
			- [4 将两个tensor\_a 和tensor\_b数乘，定义为tensor\_c](#4-将两个tensor_a-和tensor_b数乘定义为tensor_c)
			- [5 tensor\_c的数值是多少](#5-tensor_c的数值是多少-1)
	- [计算大题](#计算大题)
		- [卷积计算（灰度图像）](#卷积计算灰度图像)
			- [1 根据卷积以上输入数据和卷积核给出每次卷积的过程。（12'）](#1-根据卷积以上输入数据和卷积核给出每次卷积的过程12)
			- [2 最终的特征图是什么？(3')](#2-最终的特征图是什么3)
		- [多通道（彩色图像）](#多通道彩色图像)
			- [1 请给出每次卷积的过程。(12')](#1-请给出每次卷积的过程12)
			- [2 最终的特征图是什么？(3')](#2-最终的特征图是什么3-1)
	- [设计题（开放性题目）](#设计题开放性题目)
		- [1\_A 中文电影评论分类的目标是什么？并说明其意义。](#1_a-中文电影评论分类的目标是什么并说明其意义)
		- [1\_B 垃圾邮件分类的目标是什么？并说明其意义。](#1_b-垃圾邮件分类的目标是什么并说明其意义)
		- [2 设计一个基于循环神经网络分类器，要考虑哪些问题。（3点）](#2-设计一个基于循环神经网络分类器要考虑哪些问题3点)
			- [2.1 电影评论的解法](#21-电影评论的解法)
			- [2.2 垃圾邮件的解法](#22-垃圾邮件的解法)
		- [列举至少2个评估模型性能的指标，并说明原因。](#列举至少2个评估模型性能的指标并说明原因)
			- [3.1 电影评论的解法](#31-电影评论的解法)
			- [3.2 垃圾邮件的解法](#32-垃圾邮件的解法)
		- [4\_a 请设计一种循环神经网络模型，用于中文电影评论情感分析，并且介绍你所设计模型的结构](#4_a-请设计一种循环神经网络模型用于中文电影评论情感分析并且介绍你所设计模型的结构)
		- [4\_b 请设计一种循环神经网络模型，用于中文电影评论情感分析，并且介绍你所设计模型的结构](#4_b-请设计一种循环神经网络模型用于中文电影评论情感分析并且介绍你所设计模型的结构)
	- [选择题 \& 判断](#选择题--判断)
		- [重点掌握部分](#重点掌握部分)
		- [非重点掌握部分](#非重点掌握部分)

---

# 正文

## 问答题

### 1 神经网络的优化方案（5条）

1. 通过改变模型待优化的参数和神经网络层数来改变网络模型的复杂度。
2. 选择更加合适的损失函数
3. 优化学习率
4. 选择更加合适的优化器
5. 数据集增强
6. 正则化
7. 使用dropout防止过拟合

---

### 2 过拟合的优化方案（5条）

数据层面：<br>
&emsp;&emsp;（1）获取更多的数据集：数据增强<br>
&emsp;&emsp;（2）数据预处理：清洗数据，筛选更高质量的特征

模型层面：<br>
&emsp;&emsp;（1）选择简单的模型<br>
&emsp;&emsp;（2）加入正则化：L1，L2正则化，降低模型的复杂度

更多方法：<br>
&emsp;&emsp;（1）加入噪声：减少频繁出现的无意义的模式<br>
&emsp;&emsp;（2）dropout：随机去除一部分的神经元


---

### 3 对公式中的参数解释

$$ \sum w_i*x_i + b = wx + b $$

&emsp;&emsp;$$ w_i $$ :权重变量<br>
&emsp;&emsp;$$ x_i $$ :数据输入变量<br>
&emsp;&emsp;$$ b $$ :偏置<br>

---

### 4（必考）列举深度学习中最常见的激活函数并说明（3条）

1. sigmoid函数：取值范围为(0,1)，它可以将一个实数映射到(0,1)的区间。
2. tanh函数：tanh函数也叫也称为双切正切函数，取值范围为[-1,1]。
3. ReLU函数：将负数映射为0，将正数保留不变。
4. Softmax函数：将一组任意实数值映射到一个概率分布，其中每个值都是正的并且总和等于1。
5. Leaky ReLU函数：在负区域返回一个小的斜率而不是0。

---

### 5 CNN的基本结构，有哪些基本模块和功能

基本组成单元:<br>
&emsp;&emsp;具有可学习的权重和偏置的神经元组成

基本层级构造<br>
&emsp;&emsp;输入层：数据的输入（通常是图像）<br>
&emsp;&emsp;卷积层：使用卷积进行特征提取和映射<br>
&emsp;&emsp;激活函数：增加非线性映射<br>
&emsp;&emsp;池化层：下采样，对特征图稀疏处理，减少数据运算量<br>
&emsp;&emsp;全连接层：通常在尾部，对数据重新拟合并输出分类结果

---

### 6 卷积神经网络相关问题

#### 6.1 卷积神经网络主要工作是什么？
&emsp;&emsp;提取特征。

#### 6.2 池化层的池化作用

&emsp;&emsp;作用：降维,缩减模型大小。提高计算速度<br>

#### 6.3简述两种池化方式

最大池化：<br>
&emsp;&emsp;输入张量中的每个窗口映射到该窗口中的最大值。它能够保留局部特征的最大值并压缩输入的空间维度

均值池化：<br>
&emsp;&emsp;将输入张量中的每个窗口映射到该窗口中的平均值。它能够对输入进行平滑处理并压缩输入的空间维度。

---

### 7 对一些名词的解释

#### Epoch
&emsp;&emsp;表示整个数据集的一次迭代。

#### Batch
&emsp;&emsp;指的是不能一次性将整个数据集传递给神经网络，所以我们将数据集分成几个批处理，每一批称为Batch

#### interation
&emsp;&emsp;迭代的次数。例如我们有10000张图像作为数据，Batch大小为200。那么一个Epoch 应该运行50次Iteration(10,000除以200)。

---

## 编程题

### A卷

#### 1 导入tensorflow模块并命名为tf

```python
import tensorflow as tf
```

#### 2 利用constent创建一个形状为2*2，数值分别为[1,2,3,4]，类型为float的常量tensor_a

```python
tensor_a = tf.constent([[1,2,3,4]],shape=[2,2],dtype=tf.float32)
```

#### 3 创建一个形状为2*2的变量tensor_b，并且b中的每个元素的值为1

```python
tensor_b = tf.Variable(tf.ones([2,2]))
```

#### 4 将两个tensor_a和tensor_b相加，定义为tensor_c

```python
c = tf.add(tensor_a,tensor_b)
```

#### 5 tensor_c的数值是多少

以下是完整的输出(你只需要写`array`中的内容即可)
```py
>>> c

<tf.Tensor:shape=(2,2),dtype=float32,numpy=
array([[2.,3.],
       [4.,5.]], dtype=float32)>
```

---

### B卷

#### 1 导入tensorflow模块并命名为tf

```python
import tensorflow as tf
```

#### 2 利用constent创建一个形状为3*2，数值分别为[1,2,3,4,5,6]，类型为float的常量tensor_a

```python
tensor_a = tf.constent([[1,2,3,4,5,6]],shape=[3,2],dtype=tf.float32)
```

#### 3 创建一个形状为2*2的变量tensor_b，并且b中的每个元素的值为1

```python
tensor_b = tf.Variable(tf.ones([2,2]))
```

#### 4 将两个tensor_a 和tensor_b数乘，定义为tensor_c

```python
tensor_c = tf.matmul(tensor_a,tensor_b)
```

#### 5 tensor_c的数值是多少

以下是完整的输出(你只需要写`array`中的内容即可)

```py
>>> c

<tf.Tensor:shape=(2,2),dtype=float32,numpy=
array([[3.,3.],
       [7.,7.],
       [11.,11.]], dtype=float32)>
```

---

## 计算大题

> 以下图片只是做一个示例，考试时请自行计算，要求，每一步都必须要写到位，每一个像素值都需要计算<br>
> 示例中空白的部分在考试时需要补全

### 卷积计算（灰度图像）

{% include aligner.html images="blog-img/artificialNetwork/3.jpg" column=1 %}

#### 1 根据卷积以上输入数据和卷积核给出每次卷积的过程。（12'）

{% include aligner.html images="blog-img/artificialNetwork/4.jpg" column=1 %}

#### 2 最终的特征图是什么？(3')

{% include aligner.html images="blog-img/artificialNetwork/5.jpg" column=2 %}

---

### 多通道（彩色图像）

#### 1 请给出每次卷积的过程。(12')

{% include aligner.html images="blog-img/artificialNetwork/1.jpg" column=1 %}

#### 2 最终的特征图是什么？(3')

{% include aligner.html images="blog-img/artificialNetwork/2.jpg" column=1 %}

---

## 设计题（开放性题目）

本题针对两个题面进行分析，分别是：“中文电影评论情感分析”、“垃圾邮件分类”。

### 1_A 中文电影评论分类的目标是什么？并说明其意义。

&emsp;&emsp;目标：对电影评论进行分类。<br>
&emsp;&emsp;意义：根据模型识别出电影的评论是正面的还是负面的，有助于对电影做出定性的分析。

### 1_B 垃圾邮件分类的目标是什么？并说明其意义。

&emsp;&emsp;目标：对邮件进行分类<br>
&emsp;&emsp;意义：将邮件分为，有用邮件和垃圾邮件，有助于对邮件做出定性的分析。

---

### 2 设计一个基于循环神经网络分类器，要考虑哪些问题。（3点）

#### 2.1 电影评论的解法

1. 数据的处理问题：需要收集电影评论数据并进行清洗、去重、分词等预处理操作。
2. 模型的选择问题：选择双向LSTM神经网络，作为该神经网络的分类器。因为双向LSTM可以同时考虑历史和未来的信息，从而更好地预测当前时间步的输出。
3. 训练方式的选择：使用监督学习的方式训练LSTM网络分类器。使用数据量较大时考虑使用采用批量训练的方式。
4. 模型评估的方法选择：结合交叉验证来评估模型性能。
5. 要防止过拟合的发生：采用一些正则化技术，如L1、L2正则化和dropout等方法来缓解。

#### 2.2 垃圾邮件的解法

1. 数据的处理问题：需要收集邮件数据并进行清洗、去重、分词等预处理操作。
2. 模型的选择问题：选择双向LSTM神经网络，作为该神经网络的分类器。因为双向LSTM可以同时考虑历史和未来的信息，从而更好地预测当前时间步的输出。
3. 训练方式的选择：使用监督学习的方式训练LSTM网络分类器。使用数据量较大时考虑使用采用批量训练的方式。
4. 模型评估的方法选择：结合交叉验证来评估模型性能。
5. 要防止过拟合的发生：采用一些正则化技术，如L1、L2正则化和dropout等方法来缓解。

### 列举至少2个评估模型性能的指标，并说明原因。

#### 3.1 电影评论的解法

1. 准确率：它表示分类器正确预测样本标签的比例。在电影情感分析任务中，准确率可以告诉我们分类器正确预测情感极性评论的比例。
2. 召回率：指实际为正例的样本中被分类器正确识别为正例的比例。在情感分析中，召回率可以衡量分类器正确捕捉到所有积极或消极评论的能力。
3. AUC值：AUC值越大，则分类器的性能越好，在正负样本不平衡时可以使用。
4. F1值：分数是准确率和召回率的加权平均值，它综合了两者的影响。F1分数越高，则分类器的性能越好。


#### 3.2 垃圾邮件的解法

1. 准确率：它表示分类器正确预测样本标签的比例。在电影情感分析任务中，在垃圾邮件分类任务中，准确率可以告诉我们分类器正确预测垃圾邮件或非垃圾邮件的比例。。
2. 召回率：指实际为正例的样本中被分类器正确识别为正例的比例。在垃圾邮件分类中，召回率可以衡量分类器正确捕捉到所有垃圾邮件的能力。
3. AUC值：AUC值越大，则分类器的性能越好，在正负样本不平衡时可以使用。
4. F1值：分数是准确率和召回率的加权平均值，它综合了两者的影响。F1分数越高，则分类器的性能越好。

### 4_a 请设计一种循环神经网络模型，用于中文电影评论情感分析，并且介绍你所设计模型的结构

这里选用LSTM循环神经网络

1. 输入层：接受原始文本数据，即需要进行情感分类的中文电影评论，将每一个中文文本转化为词向量。
2. Embedding Layer（嵌入层）：使用预训练的中文词向量来初始化嵌入层参数。
3. LSTM层：按顺序处理每个词向量，并输出相应的隐藏状态向量和记忆状态向量。
4. 全局最大池化层：提取整个序列的最大特征向量，减少模型复杂度并提高泛化性能。在此模型中，用全局最大池化来得到固定长度的特征向量。
5. 全连接层：全连接层接收全局池化层的输出，可以进一步提取高级特征，并通过ReLU激活函数进行非线性映射。
6. Sigmoid层：输出层采用Sigmoid函数作为激活函数，将全连接层的输出映射到0~1之间。
7. Output（输出层）：生成最终的模型预测结果，即电影评论的正向与负向

最后使用交叉熵损失函数作为目标函数，使用反向传播算法进行参数更新。

### 4_b 请设计一种循环神经网络模型，用于中文电影评论情感分析，并且介绍你所设计模型的结构

这里选用LSTM循环神经网络

1. 输入层：接受原始文本数据，即需要进行分类的邮件信息，将每一个文本转化为词向量。
2. Embedding Layer（嵌入层）：使用预训练的词向量来初始化嵌入层参数。
3. LSTM层：按顺序处理每个词向量，并输出相应的隐藏状态向量和记忆状态向量。
4. 全局最大池化层：提取整个序列的最大特征向量，减少模型复杂度并提高泛化性能。在此模型中，用全局最大池化来得到固定长度的特征向量。
5. 全连接层：全连接层接收全局池化层的输出，可以进一步提取高级特征，并通过ReLU激活函数进行非线性映射。
6. Sigmoid层：输出层采用Sigmoid函数作为激活函数，将全连接层的输出映射到0~1之间。
7. Output（输出层）：生成最终的模型预测结果，即邮件是否为垃圾邮件的评定。

最后使用交叉熵损失函数作为目标函数，使用反向传播算法进行参数更新。

---

## 选择题 & 判断

### 重点掌握部分

1.【单选】
以下关于深度学习描述正确的是

		A. 深度学习是机器学习的一个分支
		B. 深度学习与机器学习是互相包含的关系
		C. 深度学习与机器学习同属于人工智能但相互之间没有关系
		D. 以上都不对

正确答案：A

2.【单选】
传统机器学习和深度学习是人工智能核心技术，在工程流程上略有差别，以下步骤在深度学习中不需要做的是

		A. 模型评估
		B. 特征工程
		C. 数据清洗
		D. 模型构建

正确答案：B

3.【单选】
是指根据文本所表达的含义和情感信息将文本划分成褒扬的或贬义的两种或几种类型，是对文本作者倾向性和观点、态度的划分，因此有时也称倾向性分析。

		A. 语音识别
		B. 机器学习
		C. 自然语言处理
		D. 情感分类

正确答案：D

4.【单选】
下列有关单层感知器的说法错误的是？（  ）

		A. 包含输入层、隐藏层和输出层
		B. 包含求和和激活操作
		C. 能够解决“与门”操作
		D. “与门”的线性分割线的斜率有权值决定

正确答案：A

5.【单选】
若输入x1=1，x2=0，对应的权值分别为0.5，0.5，则经过过sign函数后的值是多少？（  ）

		A. 0
		B. 1

正确答案：B


6.【单选】
如果我们希望预测n个类（p1，p2 ... pk）的概率使得所有n的p的和等于1，那么下列哪个函数可以用作输出层中的激活函数？（  ）

		A. softmax
		B. ReLU
		C. Sigmoid
		D. Tanh

正确答案：A


7.【单选】
将Sigmoid激活函数改为ReLu，将有助于克服梯度消失问题？（  ）

		A. 对
		B. 错

正确答案：A

8.【单选】
Sigmoid是神经网络中最常用到的一种激活函数，除非当梯度太大导致激活函数被弥散，这叫作神经元饱和。

{% include aligner.html images="blog-img/artificialNetwork/6.png" column=1 %}

这就是为什么ReLU会被提出来，因为ReLU可以使得梯度在正向时输出值与原始值一样。

{% include aligner.html images="blog-img/artificialNetwork/7.png" column=1 %}

这是否意味着在神经网络中ReLU单元永远不会饱和?（）

		A. 对的
		B. 错的

正确答案：B

9.【单选】
您正在构建一个用于识别黄瓜（y=1）和西瓜（y=0）的二进制分类器。您建议将这些激活函数中的哪一个用于输出层？（  ）

		A. ReLU
		B. Leaky ReLU
		C. sigmoid
		D. tanh

正确答案：C

10.【单选】
假定你在神经网络中的隐藏层中使用激活函数 X。在特定神经元给定任意输入，你会得到输出「-0.0001」。X 可能是以下哪一个激活函数？（  ）

		A. ReLU
		B. tanh（x）
		C. sigmoid
		D. 以上都不是

正确答案：B

11.【单选】
DNN的全称是（）

		A. 深度神经网络
		B. 深度学习网络
		C. 动态神经网络
		D. 动态学习网络

正确答案：A

12.【单选】
下列有关全连接网络说法正确的是（  ）：

		A. 每个神经元具有激活函数功能
		B. 每一个神经元与下一层的神经元完全连接
		C. 神经元之间不存在跨层连接
		D. 以上都正确

正确答案：D


13.【单选】
在一个神经网络中，知道每一个神经元的权重和偏差是最重要的一步。如果知道了神经元准确的权重和偏差，便可以近似任何函数，但怎么获知每个神经的权重和偏移呢（  ）

		A. 搜索每个可能的权重和偏差组合，直到得到最佳值
		B. 赋予一个初始值，然后检查跟最佳值的差值，不断迭代调整权重
		C. 随机赋值
		D. 以上都不正确

正确答案：B

14.【单选】
假设神经元的输入值为（1,2,3），对应的权重为4,5,6，神经元经过一个线性函数y=2x，最终的输出结果是多少（  ）

		A. 32
		B. 64
		C. 96
		D. 48

正确答案：B

15.【单选】

下列声明哪些是正确的？（  ）

声明1：可以通过将所有权重初始化为0来训练网络

声明2：可以通过将偏差初始化为0来训练网络

		A. 1对2错
		B. 1错2对
		C. 1和2都对
		D. 1和2都错

正确答案：B

16.【单选】
我们在训练神经网络过程中，使用梯度下降法不断更新哪种数值，进而使得损失函数最小化?（）

		A. 样本数目
		B. 特征值
		C. 超参数
		D. 参数

正确答案：D

17.【单选】
在神经网络中，我们是通过以下哪个方法在训练网络的时候更新参数，从而最小化损失函数的?

		A. 正向传播算法
		B. 池化计算
		C. 卷积计算
		D. 反向传播算法

正确答案：D

18.【单选】
单层感知器能够实现异或问题的分类，这句话是否正确？（  ）

		A. 正确
		B. 错误

正确答案：B


19.【单选】
如果我们用了一个过大的学习速率会发生什么？（  ）

		A. 神经网络会收敛
		B. 不好说
		C. 都不对
		D. 神经网络不会收敛

正确答案：D

20.【单选】
在下图中，我们可以观察到误差出现了许多小的"涨落"。 这种情况我们应该担心吗？（  ）

{% include aligner.html images="blog-img/artificialNetwork/8.png" column=1 %}

		A. 需要，这也许意味着神经网络的学习速率存在问题
		B. 不需要，只要在训练集和交叉验证集上有累积的下降就可以了
		C. 不确定

正确答案：B

21.【单选】
当神经网络的调参效果不好时，需要从哪些角度考虑？（ ）

1 是否找到合适的损失函数

2 batch size是否合适

3 是否选择了和是的激活函数

4 是否选择合适的学习率

5 是否过拟合

		A. 1,3,4,5
		B. 1,2,3,4
		C. 全部都不是
		D. 全部都是

正确答案：D

22.【单选】
学习率会影响待优化的参数的收敛吗？

		A. 会
		B. 不会

正确答案：A

23.【单选】
在训练神经网络时，损失函数(loss)在最初的几个epochs时没有下降，可能的原因是？（  ）

{% include aligner.html images="blog-img/artificialNetwork/9.png" column=1 %}

		A. 学习率太高
		B. 正则参数太高
		C. 陷入局部最小值
		D. 以上都有可能

正确答案：D

24.【单选】学习率（），会导致待优化的参数在最小值附近波动，不收敛；学习率（），会导致待优化的参数收敛缓慢。

		A. 过小；过大
		B. 过大；过小
		C. 过大；过大
		D. 过小；过小

正确答案：B

25.【单选】当训练一个神经网络来作图像识别任务时，通常会绘制一张训练集误差和交叉训练集误差图来进行调试。

{% include aligner.html images="blog-img/artificialNetwork/10.png" column=1 %}

在上图中，最好在哪个时间停止训练？（  ）

		A. A
		B. B
		C. C
		D. D

正确答案：C


26.【单选】
在选择神经网络的深度时，下面哪些参数需要考虑？（  ）

1 神经网络的类型(如MLP,CNN)

2 输入数据

3 计算能力(硬件和软件能力决定)

4 学习速率

5 映射的输出函数

		A. 1,2,3,5
		B. 2,3,4,5
		C. 都需要
		D. 1,3,4,5

正确答案：C

27.【单选】
Dropout对一个神经元随机屏蔽输入权重这句话是否正确？（  ）



		A. 正确的
		B. 错误的

正确答案：B

28.【单选】
在一个神经网络中，下面哪种方法可以用来处理过拟合？（  ）

		A. dropout
		B. 分批归一化
		C. 正则化
		D. 以上都可以

正确答案：D


29.【单选】
下列的哪种方法可以用来降低深度学习模型的过拟合问题？（  ）

1 增加更多的数据

2 使用数据扩增技术(data augmentation)

3 使用归纳性更好的架构

4 正规化数据

5 降低架构的复杂度

		A. 1,4,5
		B. 1,2,3
		C. 1,3,4,5
		D. 所有都可以

正确答案：D

30.【单选】
数据规一化(Normalization)的好处都有啥？（  ）

		A. 让每一层的输入的范围都大致固定
		B. 它将权重的归一化平均值和标准差
		C. 它是一种非常有效的反向传播(BP)方法
		D. 以上都不正确

正确答案：A


31.【单选】
单层的神经网络反向传播算法也适用多层神经网络的反向传播，这句话正确吗？（  ）

		A. 正确
		B. 不正确

正确答案：B

32.【单选】前馈神经网络是指网络只能前向传播，不能后向传播，这句话是否正确（  ）

		A. 正确的
		B. 错误的

正确答案：B

33.【单选】
“所谓的权值共享就是说，用一个卷积核去卷积一张图，这张图每个位置是被同样数值的卷积核操作的，权重是一样的”，这句话是否正确

		A. 正确
		B. 错误
		C. 不确定

正确答案：A

34.【单选】
CNN是卷积神经网络，它的关键层有哪些？（ ）1 输入层2 卷积层3 激活层4 池化层5 全连接层

		A. 1,2,3,4
		B. 1,2,3,4,5
		C. 2,4

正确答案：B

35.【单选】
关于循环神经网络以下说法错误的是?

		A. 循环神经网络可以根据时间轴展开
		B. LSTM 无法解决梯度消失的问题
		C. LSTM 也是一种循环神经网络
		D. 循环神经网络可以简写为 RNN

正确答案：B

36.【单选】
关于循环神经网络，哪个不是LSTM的门?

		A. 输入门
		B. 遗忘门
		C. 输出门
		D. 更新门

正确答案：D

37.【单选】
“门”的出现可以帮助防止在RNN中的梯度消失问题。（ ）

		A. 对
		B. 错

正确答案：A

38.【单选】
以下关于标准 RNN 模型，说法正确的是?

		A. 不存在一对一的模型结构
		B. 反向传播时不考虑时间方向
		C. 不存在多对多的模型结构
		D. 会出现长时间传输记忆的信息衰减的问题

正确答案：D

39.【单选】深度学习可以用在下列哪些NLP任务中？（  ）

		A. 情感分析
		B. 问答系统
		C. 机器翻译
		D. 所有选项

正确答案：D


40.【单选】给定一个长度为n的不完整单词序列，我们希望预测下一个字母是什么。比如输入是“predictio”(9个字母组成)，希望预测第十个字母是什么。下面哪种神经网络结构适用于解决这个工作？（  ）

		A. 循环神经网络
		B. 卷积神经网络
		C. 全连接神经网络
		D. 以上都不是

正确答案：A


41.【单选】以下哪项任务优先选择使用卷积神经网络来实现

		A. 图像数据获取
		B. 图像预处理
		C. 图像特征提取
		D. 图像数据增强

正确答案：C


42.【单选】
对于一个图像识别问题(在一张照片里找出一只猫)，下面哪种神经网络可以更好地解决这个问题？（  ）

		A. 循环神经网络
		B. 感知机
		C. 多层感知机
		D. 卷积神经网络

正确答案：D

43.【单选】
在训练CNN时，可以对输入进行旋转、平移、缩放等预处理提高模型泛化能力。这么说是对，还是不对？（  ）

		A. 对
		B. 不对

正确答案：A

44.【单选】
一个32X32大小的图像，通过步长为4，尺寸为4X4的池化运算后，尺寸变为

		A. 14X14
		B. 2X2
		C. 28X28
		D. 8X8

正确答案：D

45.【单选】
图像卷积处理中，例如32X32，strides=1，padding="VALID"，FILTER卷积核3*3，则经过卷积处理之后图像尺寸变为?

		A. 28X28
		B. 14X14
		C. 30X30
		D. 32X32

正确答案：C

---

### 非重点掌握部分

1.【单选】给定一个长度为n的不完整单词序列，我们希望预测下一个字母是什么。比如输入是“predictio”(9个字母组成)，希望预测第十个字母是什么。下面哪种神经网络结构适用于解决这个工作？（  ）

		A. 循环神经网络
		B. 卷积神经网络
		C. 全连接神经网络
		D. 以上都不是

正确答案：A


2.【单选】关于循环神经网络，哪个不是LSTM的门?

		A. 输入门
		B. 遗忘门
		C. 输出门
		D. 更新门

正确答案：D

3.【单选】
以下哪项任务优先选择使用卷积神经网络来实现

		A. 图像数据获取
		B. 图像预处理
		C. 图像特征提取
		D. 图像数据增强

正确答案：C

4.【单选】
对于一个图像识别问题(在一张照片里找出一只猫)，下面哪种神经网络可以更好地解决这个问题？（  ）

		A. 循环神经网络
		B. 感知机
		C. 多层感知机
		D. 卷积神经网络

正确答案：D

5.【单选】
若输入x1=1，x2=0，对应的权值分别为0.5，0.5，则经过过sign函数后的值是多少？（  ）

		A. 0
		B. 1

正确答案：B

6.【单选】
在神经网络中，我们是通过以下哪个方法在训练网络的时候更新参数，从而最小化损失函数的?

		A. 正向传播算法
		B. 池化计算
		C. 卷积计算
		D. 反向传播算法

正确答案：D

7.【单选】单层的神经网络反向传播算法也适用多层神经网络的反向传播，这句话正确吗？（  ）

		A. 正确
		B. 不正确

正确答案：B

8.【单选】前馈神经网络是指网络只能前向传播，不能后向传播，这句话是否正确（  ）

		A. 正确的
		B. 错误的

正确答案：B

9.【单选】
学习率（），会导致待优化的参数在最小值附近波动，不收敛；学习率（），会导致待优化的参数收敛缓慢。

		A. 过小；过大
		B. 过大；过小
		C. 过大；过大
		D. 过小；过小

正确答案：B

10.【单选】
学习率会影响待优化的参数的收敛吗？

		A. 会
		B. 不会

正确答案：A

11.【单选】
下列有关LSTM的细胞状态正确的是。（）

		A. LSTM决定从细胞状态中丢弃什么信息
		B. LSTM决定什么信息增加到细胞状态中
		C. LSTM决定从细胞状态中输出什么信息
		D. 以上都是

正确答案：D

12.【单选】
关于循环神经网络，哪个不是LSTM的门?

		A. 输入门
		B. 遗忘门
		C. 输出门
		D. 更新门

正确答案：D

13.【单选】
给定一个长度为n的不完整单词序列，我们希望预测下一个字母是什么。比如输入是“predictio”(9个字母组成)，希望预测第十个字母是什么。下面哪种神经网络结构适用于解决这个工作？（  ）

		A. 循环神经网络
		B. 卷积神经网络
		C. 全连接神经网络
		D. 以上都不是

正确答案：A


14.【单选】
构建一个神经网络，将前一层的输出和它自身作为输入。

{% include aligner.html images="blog-img/artificialNetwork/11.png" column=1 %}

下列哪一种架构有反馈连接？（  ）

		A. 循环神经网络
		B. 卷积神经网络
		C. 限制玻尔兹曼机
		D. 以上都不正确

正确答案：A

15.【单选】
“门”的出现可以帮助防止在RNN中的梯度消失问题。（ ）

		A. 对
		B. 错

正确答案：A

16.【单选】
以下关于标准 RNN 模型，说法正确的是?

		A. 不存在一对一的模型结构
		B. 反向传播时不考虑时间方向
		C. 不存在多对多的模型结构
		D. 会出现长时间传输记忆的信息衰减的问题

正确答案：D

17.【单选】
以下关于标准 RNN 模型，说法正确的是?

		A. 不存在一对一的模型结构
		B. 反向传播时不考虑时间方向
		C. 不存在多对多的模型结构
		D. 会出现长时间传输记忆的信息衰减的问题

正确答案：D

18.【单选】
一个循环神经网络可以被展开成为一个完全连接的、具有无限长度的普通神经网络，这种说法是（  ）。

		A. 正确的
		B. 错误的

正确答案：A

19.【单选】
输入图片大小为200×200，依次经过一层卷积（kernel size 5×5，same padding ，stride 2），pooling（kernel size 3×3，valid padding ，stride 1），又一层卷积（kernel size 3×3，same padding，stride 1）之后，输出特征图大小为（  ）

		A. 96
		B. 97
		C. 98

正确答案：C

20.【单选】
增加卷积核的大小对于改进卷积神经网络的效果是必要的吗？（  ）

		A. 没听说过
		B. 是
		C. 否
		D. 不知道

正确答案：C

21.【单选】
在训练CNN时，可以对输入进行旋转、平移、缩放等预处理提高模型泛化能力。这么说是对，还是不对？（  ）

    	A. 对
		B. 不对

正确答案：A

22.【单选】
当构建一个神经网络进行图片的语义分割时，通常采用下面哪种顺序？（  ）

		A. 先用卷积神经网络处理输入，再用反卷积神经网络得到输出
		B. 先用反卷积神经网络处理输入，再用卷积神经网络得到输出
		C. 不确定

正确答案：A

23.【单选】
假设下方是传入最大池化层的一个输入，该层中神经元的池化大小为(3,3)

{% include aligner.html images="blog-img/artificialNetwork/12.png" column=1 %} 

那么，该池化层的输出是多少？（  ）

		A. 3
		B. 7
		C. 5
		D. 5.5

正确答案：B

24.【单选】在一个神经网络中，下面哪种方法可以用来处理过拟合？（  ）


		A. dropout
		B. 分批归一化
		C. 正则化
		D. 以上都可以

正确答案：D


25.【单选】下列的哪种方法可以用来降低深度学习模型的过拟合问题？（  ）

1 增加更多的数据

2 使用数据扩增技术(data augmentation)

3 使用归纳性更好的架构

4 正规化数据

5 降低架构的复杂度

		A. 1,4,5
		B. 1,2,3
		C. 1,3,4,5
		D. 所有都可以

正确答案：D


26.【多选】优化神经网络可以从哪些方面入手？（）

		A. 学习率的优化
		B. 梯度下降的优化
		C. 过拟合和欠拟合的优化
		D. 梯度的优化

正确答案：A,B,C

27.【单选】当神经网络的调参效果不好时，需要从哪些角度考虑？（ ）

1 是否找到合适的损失函数

2 batch size是否合适

3 是否选择了和是的激活函数

4 是否选择合适的学习率

5 是否过拟合

		A. 1,3,4,5
		B. 1,2,3,4
		C. 全部都不是
		D. 全部都是

正确答案：D


28.【单选】过拟合和欠拟合的优化不包括以下哪种方法？（）

		A. Dropout
		B. Bagging
		C. 梯度下降法
		D. 正则化

正确答案：C


29.【单选】单层的神经网络反向传播算法也适用多层神经网络的反向传播，这句话正确吗？（  ）

		A. 正确
		B. 不正确

正确答案：B


30.【单选】一个完成的反向传播的步骤是（  ）

1 将隐藏层误差反向传播给输入层，调节隐藏层到输入层的权值和阈值

2 将输出层的误差反向传播给隐藏层，调整隐藏层到输出层的权值和阈值

3 将隐藏层的误差反向传播给隐藏层，调节隐藏层到隐藏层的权值和阈值

		A. 1 2 3
		B. 2 1 3
		C. 1 3 2
		D. 2 3 1

正确答案：D


31.【单选】已知：

- 大脑是有很多个叫做神经元的东西构成，神经网络是对大脑的简单的数学表达。

- 每一个神经元都有输入、处理函数和输出。

- 神经元组合起来形成了网络，可以拟合任何函数。

- 为了得到最佳的神经网络，我们用梯度下降方法不断更新模型

给定上述关于神经网络的描述，什么情况下神经网络模型被称为深度学习模型？（  ）

		A. 加入更多层，使神经网络的深度增加
		B. 有维度更高的数据
		C. 当这是一个图形识别的问题
		D. 以上都不正确

正确答案：A

32.【单选】前馈神经网络是指网络只能前向传播，不能后向传播，这句话是否正确（  ）

		A. 正确的
		B. 错误的

正确答案：B


33.【单选】反向传播算法一开始计算什么内容的梯度，之后将其反向传播？（  ）

		A. 预测结果与样本标签之间的误差
		B. 各个输入样本的平方差之和
		C. 各个网络权重的平方差之和
		D. 以上都不对

正确答案：A

34.【单选】下图中的数据是线性可分的么？（  ）

{% include aligner.html images="blog-img/artificialNetwork/13.png" column=1 %}  


		A. 是
		B. 否

正确答案：B

35.【单选】下列有关单层感知器的说法错误的是？（  ）

		A. 包含输入层、隐藏层和输出层
		B. 包含求和和激活操作
		C. 能够解决“与门”操作
		D. “与门”的线性分割线的斜率有权值决定

正确答案：A

36.【单选】神经网络结构的选择会影响训练模型的效果，神经元结构不包括哪方面的选择。（）

		A. depth
		B. width
		C. connectivity
		D. function

正确答案：D

37.【多选】神经网络模型的效果受神经元结构的影响，受哪方面的选择。（）

		A. depth
		B. width
		C. connectivity
		D. function

正确答案：A,B,C

38.【单选】传统机器学习和深度学习是人工智能核心技术，在工程流程上略有差别，以下步骤在深度学习中不需要做的是

		A. 模型评估
		B. 特征工程
		C. 数据清洗
		D. 模型构建

正确答案：B

39.【单选】如果我们用了一个过大的学习速率会发生什么？（  ）

		A. 神经网络不会收敛
		B. 不好说
		C. 都不对
		D. 神经网络会收敛

正确答案：A

40.【单选】过拟合和欠拟合的优化不包括以下哪种方法？（）

		A. Bagging
		B. Dropout
		C. 梯度下降法
		D. 正则化

正确答案：C

41.【多选】神经网络中优化方法有（）

		A. Adam
		B. 随机梯度下降法
		C. 随机下降法
		D. 梯度下降法

正确答案：A,B,D

42.【单选】在选择神经网络的深度时，下面哪些参数需要考虑？（  ）

1 神经网络的类型(如MLP,CNN)

2 输入数据

3 计算能力(硬件和软件能力决定)

4 学习速率

5 映射的输出函数

		A. 都需要
		B. 2,3,4,5
		C. 1,2,3,5
		D. 1,3,4,5

正确答案：A

43.【单选】当训练一个神经网络来作图像识别任务时，通常会绘制一张训练集误差和交叉训练集误差图来进行调试。

{% include aligner.html images="blog-img/artificialNetwork/14.png" column=1 %} 

在上图中，最好在哪个时间停止训练？（  ）

		A. C
		B. B
		C. D
		D. A

正确答案：A

44.【单选】当数据太大而不能同时在RAM中处理时，哪种梯度技术更有优势？（ ）

		A. 随机梯度下降(Stochastic Gradient Descent)
		B. 全批量梯度下降(Full Batch Gradient Descent )

正确答案：A

45.【单选】当神经网络的调参效果不好时，需要从哪些角度考虑？（ ）

1 是否找到合适的损失函数

2 batch size是否合适

3 是否选择了和是的激活函数

4 是否选择合适的学习率

5 是否过拟合

		A. 1,3,4,5
		B. 全部都是
		C. 1,2,3,4
		D. 全部都不是

正确答案：B

46.【单选】下列的哪种方法可以用来降低深度学习模型的过拟合问题？（  ）

1 增加更多的数据

2 使用数据扩增技术(data augmentation)

3 使用归纳性更好的架构

4 正规化数据

5 降低架构的复杂度

		A. 1,3,4,5
		B. 所有都可以
		C. 1,2,3
		D. 1,4,5

正确答案：B

47.【单选】在一个神经网络中，下面哪种方法可以用来处理过拟合？（  ）

		A. 分批归一化
		B. dropout
		C. 以上都可以
		D. 正则化

正确答案：C

48.【单选】下图中，红色曲线表示关于深度学习算法中每个时期的训练精度。绿色和蓝色曲线都表示验证的准确性。

{% include aligner.html images="blog-img/artificialNetwork/15.png" column=1 %} 

哪条曲线表示过拟合overfitting？（  ）

		A. 绿色曲线
		B. 蓝色曲线

正确答案：B

49.【单选】以下词语中，与卷积神经网络的概念无关的是

		A. ImageNet
		B. 超平面
		C. BP算法
		D. 特征提取

正确答案：B


50.【单选】以下哪些是CNN网络常用的模型？（  ）

1 LeNet-5

2 AlexNet

3 VGGNet

4 Google Inception Net

		A. 1,2,3,4
		B. 1,2,3
		C. 2,3

正确答案：A


51.【单选】从图中趋势可见，如果增加神经网络的宽度，精确度会增加到一个特定阈值后，便开始降低。造成这一现象的可能原因是什么？（  ）

{% include aligner.html images="blog-img/artificialNetwork/16.png" column=1 %} 

		A. 即使增加卷积核的数量，只有少部分的核会被用作预测
		B. 当卷积核数量增加时，神经网络的预测能力（Power）会降低
		C. 当卷积核数量增加时，导致过拟合
		D. 以上都不正确

正确答案：C

52.【单选】输入图像已被转换为大小为28×28的矩阵和大小为7×7的步幅为1的核心/滤波器，填充方式是valid 。卷积矩阵的大小是多少？（  ）

		A. 22 X 22
		B. 21 X 21
		C. 28 X 28
		D. 7X 7

正确答案：A

53.【多选】借助池化，网络存储可以有效提升存储的利用率，池化操作通常有几种?

		A. 平均池化
		B. 卷积
		C. 最大池化
		D. 全连接

正确答案：A,C

54.【单选】在深度学习网络中，反向传播算法用于寻求最优参数，在反向传播算法中使用的什么法则进行逐层求导的?

		A. 链式法则
		B. 累加法则
		C. 对等法则
		D. 归一法则

正确答案：A

55.【单选】一个完成的反向传播的步骤是（  ）

1 将隐藏层误差反向传播给输入层，调节隐藏层到输入层的权值和阈值

2 将输出层的误差反向传播给隐藏层，调整隐藏层到输出层的权值和阈值

3 将隐藏层的误差反向传播给隐藏层，调节隐藏层到隐藏层的权值和阈值

		A. 1 2 3
		B. 2 1 3
		C. 1 3 2
		D. 2 3 1

正确答案：D


56.【单选】前馈神经网络是指网络只能前向传播，不能后向传播，这句话是否正确（  ）

		A. 正确的
		B. 错误的

正确答案：B

57.【单选】反向传播算法一开始计算什么内容的梯度，之后将其反向传播？（  ）

		A. 预测结果与样本标签之间的误差
		B. 各个输入样本的平方差之和
		C. 各个网络权重的平方差之和
		D. 以上都不对

正确答案：A


58.【单选】单层的神经网络反向传播算法也适用多层神经网络的反向传播，这句话正确吗？（  ）

		A. 正确
		B. 不正确

正确答案：B

59.【单选】将Sigmoid激活函数改为ReLu，将有助于克服梯度消失问题？（  ）

		A. 对
		B. 错

正确答案：A

60.【单选】如果我们希望预测n个类（p1，p2 ... pk）的概率使得所有n的p的和等于1，那么下列哪个函数可以用作输出层中的激活函数？（  ）

		A. softmax
		B. ReLU
		C. Sigmoid
		D. Tanh

正确答案：A

61.【单选】您正在构建一个用于识别黄瓜（y=1）和西瓜（y=0）的二进制分类器。您建议将这些激活函数中的哪一个用于输出层？（  ）

		A. ReLU
		B. Leaky ReLU
		C. sigmoid
		D. tanh

正确答案：C

62.【单选】下列哪个函数不可以做激活函数？（  ）

		A. y=tanh(x)
		B. y=sin(x)
		C. y=max(x,0)
		D. y=2x

正确答案：D

63.【单选】在输出层不能使用以下哪种激活函数来分类图像（  ）

		A. sigmoid
		B. Tanh
		C. ReLU
		D. If（x> 5,1,0）

正确答案：C

64.【单选】下列有关单层感知器的说法错误的是？（  ）

		A. 包含输入层、隐藏层和输出层
		B. 包含求和和激活操作
		C. 能够解决“与门”操作
		D. “与门”的线性分割线的斜率有权值决定

正确答案：A

65.【单选】神经网络最基本的结构不包括（）

		A. 输入层
		B. 激活层
		C. 隐藏层
		D. 输出层

正确答案：B

66.【单选】下列有关全连接网络说法正确的是（  ）：

		A. 每个神经元具有激活函数功能
		B. 每一个神经元与下一层的神经元完全连接
		C. 神经元之间不存在跨层连接
		D. 以上都正确

正确答案：D

67.【单选】单层感知器能够实现异或问题的分类，这句话是否正确？（  ）

		A. 正确
		B. 错误

正确答案：B

68.【单选】在一个简单的MLP模型中，输入层有8个神经元，隐藏层有5个神经元，输出层有1个神经元。隐藏输出层和输入隐藏层之间的权重矩阵的大小是多少（  ）

		A. [1 X 5]，[5 X 8]
		B. [8×5]，[1×5]
		C. [5×8]，[5×1]
		D. [5×1]，[8×5]

正确答案：D

69.【单选】以下关于深度学习描述正确的是

		A. 深度学习是机器学习的一个分支
		B. 深度学习与机器学习同属于人工智能但相互之间没有关系
		C. 深度学习与机器学习是互相包含的关系
		D. 以上都不对

正确答案：A

70.【单选】在输出层不能使用以下哪种激活函数来分类图像（  ）

		A. Tanh
		B. ReLU
		C. sigmoid
		D. If（x> 5,1,0）

正确答案：B

71.【单选】相比sigmoid激活函数，relu激活函数有什么优势？(  )

		A. 防止梯度消失
		B. ReLu函数简繁计算速度快
		C. 以上都是
		D. ReLu输出具有稀疏性

正确答案：C

72.【单选】下列哪个函数不可以做激活函数？（  ）

		A. y=tanh(x)
		B. y=2x
		C. y=max(x,0)
		D. y=sin(x)

正确答案：B

73.【单选】您正在构建一个用于识别黄瓜（y=1）和西瓜（y=0）的二进制分类器。您建议将这些激活函数中的哪一个用于输出层？（  ）

    	A. Leaky ReLU
		B. tanh
		C. ReLU
		D. sigmoid

正确答案：D

74.【单选】若输入x1=1，x2=0，对应的权值分别为0.5，0.5，则经过过sign函数后的值是多少？（  ）

		A. 1
		B. 0

正确答案：A

75.【单选】如果我们希望预测n个类（p1，p2 ... pk）的概率使得所有n的p的和等于1，那么下列哪个函数可以用作输出层中的激活函数？（  ）

		A. softmax
		B. Sigmoid
		C. Tanh
		D. ReLU

正确答案：A

76.【单选】将Sigmoid激活函数改为ReLu，将有助于克服梯度消失问题？（  ）

		A. 错
		B. 对

正确答案：B

77.【单选】您正在构建一个用于识别黄瓜（y=1）和西瓜（y=0）的二进制分类器。您建议将这些激活函数中的哪一个用于输出层？（  ）

		A. tanh
		B. Leaky ReLU
		C. ReLU
		D. sigmoid

正确答案：D

78.【单选】相比sigmoid激活函数，relu激活函数有什么优势？(  )

		A. ReLu输出具有稀疏性
		B. ReLu函数简繁计算速度快
		C. 防止梯度消失
		D. 以上都是

正确答案：D

79.【单选】以下关于深度学习描述正确的是

		A. 深度学习与机器学习是互相包含的关系
		B. 深度学习是机器学习的一个分支
		C. 深度学习与机器学习同属于人工智能但相互之间没有关系
		D. 以上都不对

正确答案：B

80.【多选】一般神经网络包括（）

		A. 输入层
		B. 隐藏层
		C. 激活层
		D. 输出层

正确答案：A,B,D

81.【单选】单层感知器能够实现异或问题的分类，这句话是否正确？（  ）


		A. 正确
		B. 错误

正确答案：B

82.【多选】已知全连接神经网络的某一层的参数总量为 330,则上一层和本层的神经元数量可能为?

		A. 33 和 10
		B. 9 和 33
		C. 32 和 10
		D. 10 和 33

正确答案：A,D

83.【单选】全连接神经网络，如果输入层为44X8矩阵，那么与它相连的第一级参数矩阵最有可能为

		A. 32X32矩阵
		B. 任意尺寸矩阵
		C. 32X4矩阵
		D. 8X5矩阵

正确答案：D

84.【多选】深度学习中常用的损失函数有

		A. 均方误差损失函数
		B. L1 损失函数
		C. 交叉熵误差损失函数
		D. 自下降损失函数

正确答案：A,C

85.【单选】若输入x1=1，x2=0，对应的权值分别为0.5，0.5，则经过过sign函数后的值是多少？（  ）

		A. 0
		B. 1

正确答案：B

86.【单选】梯度下降算法的正确步骤是什么？（  ）

1 计算预测值和真实值之间的误差

2 重复迭代，直至得到网络权重的最佳值

3 把输入传入网络，得到输出值

4 用随机值初始化权重和偏差

5 对每一个产生误差的神经元，调整相应的（权重）值以减小误差

		A. 3，2，1，5，4
		B. 5，4，3，2，1
		C. 1，2，3，4，5
		D. 4，3，1，5，2 ​

正确答案：D

87.【单选】假设神经元的输入值为（1,2,3），对应的权重为4,5,6，神经元经过一个线性函数y=2x，最终的输出结果是多少（  ）

		A. 64
		B. 32
		C. 48
		D. 96

正确答案：A

88.【单选】我们在训练神经网络过程中，使用梯度下降法不断更新哪种数值，进而使得损失函数最小化?（）

		A. 样本数目
		B. 特征值
		C. 参数
		D. 超参数

正确答案：C

89.【单选】神经元的网络计算公式中，各参数代表的含义错误的是（）

{% include aligner.html images="blog-img/artificialNetwork/17.png" column=1 %} 

		A. b 为偏置值
		B. z 为真实结果
		C. x 为输入
		D. w 为权重

正确答案：B

90.【单选】在神经网络中，我们是通过以下哪个方法在训练网络的时候更新参数，从而最小化损失函数的?

		A. 反向传播算法
		B. 池化计算
		C. 正向传播算法
		D. 卷积计算

正确答案：A

91.【单选】优化器是训练神经网络的重要组成部分，使用优化器的目的不包含以下哪项

		A. 加快算法收敛速度
		B. 避过局部极值
		C. 减少手工参数的设置难度
		D. 避过过拟合问题

正确答案：D

92.【单选】神经网络最基本的结构不包括（）

		A. 隐藏层
		B. 输出层
		C. 输入层
		D. 激活层

正确答案：D

93.【单选】DNN的全称是（）

		A. 动态神经网络
		B. 深度学习网络
		C. 动态学习网络
		D. 深度神经网络

正确答案：D

94.【单选】下列有关全连接网络说法正确的是（  ）：

		A. 每个神经元具有激活函数功能
		B. 神经元之间不存在跨层连接
		C. 以上都正确
		D. 每一个神经元与下一层的神经元完全连接

正确答案：C

95.【单选】下列有关张量和和变量的说法正确的是（  ）

		A. 张量可以简单理解为多维度数组
		B. 在TensorFlow中所有的数据都是通过张量的形式表示“
		C. 变量是一种特殊的张量
		D. 以上都是

正确答案：D

96.【单选】TensorFlow的说法哪些是正确的（  ）

A  TensorFlow是由谷歌在2015年年底推出的一款开源框架

B  TensorFlow是基于DistDelief进行研发的第二代人工智能系统，用来快速实现深度学习（DL）和卷积神经网络（CNN）等各种算法

C  TensorFlow名字描述了执行的原理：Tensor（张量）意味着N维数组，Flow（流）意味着基于数据流图的计算

D  以上都是

		A. A
		B. D
		C. B
		D. C

正确答案：B

97.【单选】深度学习与机器学习算法之间的区别在于，深度学习过程中无需进行特征提取工作，也就是说，我们建议在进行深度学习过程之前要首先完成特征提取的工作。这种说法是（  ）

		A. 正确的
		B. 错误的

正确答案：B

98.【单选】有关数据的流向机制描述正确的是（  ）

		A. 注入机制是feed，取出机制是fetch
		B. 取出机制，即向模式中输入数据
		C. 注入机制，即从模式中得到结果
		D. 注入机制是fetch，取出机制是feed

正确答案：A

99.【单选】有关“图”描述错误的是（  ）

		A. “图”会在会话中被启动
		B. 使用Graph函数生成新的计算图
		C. 一个“图”代表一个或多个计算任务
		D. 不同计算图上的张量和运算不共享

正确答案：C

100.【单选】Dropout对一个神经元随机屏蔽输入权重这句话是否正确？（  ）


		A. 正确的
		B. 错误的

正确答案：B

101.【单选】当神经网络的调参效果不好时，需要从哪些角度考虑？（ ）

1 是否找到合适的损失函数

2 batch size是否合适

3 是否选择了和是的激活函数

4 是否选择合适的学习率

5 是否过拟合

		A. 1,3,4,5
		B. 1,2,3,4
		C. 全部都不是
		D. 全部都是

正确答案：D

102.【单选】学习率（），会导致待优化的参数在最小值附近波动，不收敛；学习率（），会导致待优化的参数收敛缓慢。

		A. 过小；过大
		B. 过大；过小
		C. 过大；过大
		D. 过小；过小

正确答案：B

103.【单选】学习率会影响待优化的参数的收敛吗？

		A. 会
		B. 不会
		
正确答案：A

104.【单选】在训练神经网络时，损失函数(loss)在最初的几个epochs时没有下降，可能的原因是？（  ）

{% include aligner.html images="blog-img/artificialNetwork/18.png" column=1 %} 

		A. 学习率太高
		B. 正则参数太高
		C. 陷入局部最小值
		D. 以上都有可能

正确答案：D


105.【单选】下列哪个不是自适应学习率优化器？()

		A. AdamGrad优化器
		B. Adam 优化器
		C. 梯度下降优化器
		D. RMSDrop优化器

正确答案：C

106.【单选】如果我们用了一个过大的学习速率会发生什么？（  ）

		A. 神经网络会收敛
		B. 不好说
		C. 都不对
		D. 神经网络不会收敛

正确答案：D

107.【单选】当训练一个神经网络来作图像识别任务时，通常会绘制一张训练集误差和交叉训练集误差图来进行调试。

{% include aligner.html images="blog-img/artificialNetwork/19.png" column=1 %} 

在上图中，最好在哪个时间停止训练？（  ）

		A. A
		B. B
		C. C
		D. D

正确答案：C

108.【单选】当数据太大而不能同时在RAM中处理时，哪种梯度技术更有优势？（ ）

		A. 全批量梯度下降(Full Batch Gradient Descent )
		B. 随机梯度下降(Stochastic Gradient Descent)

正确答案：B

109.【单选】过拟合和欠拟合的优化不包括以下哪种方法？（）

		A. Dropout
		B. Bagging
		C. 梯度下降法
		D. 正则化

正确答案：C

110.【单选】下列的哪种方法可以用来降低深度学习模型的过拟合问题？（  ）

1 增加更多的数据

2 使用数据扩增技术(data augmentation)

3 使用归纳性更好的架构

4 正规化数据

5 降低架构的复杂度

		A. 1,4,5
		B. 1,2,3
		C. 1,3,4,5
		D. 所有都可以

正确答案：D

111.【单选】在一个神经网络中，下面哪种方法可以用来处理过拟合？（  ）

		A. dropout
		B. 分批归一化
		C. 正则化
		D. 以上都可以

正确答案：D

112.【多选】优化神经网络可以从哪些方面入手？（）

		A. 学习率的优化
		B. 梯度下降的优化
		C. 过拟合和欠拟合的优化
		D. 梯度的优化

正确答案：A,B,C

113.【多选】神经网络中优化方法有（）

		A. 梯度下降法
		B. 随机梯度下降法
		C. Adam
		D. 随机下降法

正确答案：A,B,C

114.【单选】如图所示，当开始训练时，误差一直很高，这是因为神经网络在往全局最小值前进之前一直被卡在局部最小值里。为了避免这种情况，我们可以采取下面哪种策略？（  ）

{% include aligner.html images="blog-img/artificialNetwork/20.png" column=1 %} 

		A. 改变学习速率，比如一开始的几个训练周期不断更改学习率速率
		B. 一开始将学习速率减小10倍，然后用动量项(momentum)
		C. 增加参数数目，这样神经网络就不会卡在局部最优处
		D. 以上都不对

正确答案：A

115.【单选】在深度学习网络中，反向传播算法用于寻求最优参数，在反向传播算法中使用的什么法则进行逐层求导的?

		A. 链式法则
		B. 累加法则
		C. 对等法则
		D. 归一法则

正确答案：A

116.【单选】前馈神经网络是指网络只能前向传播，不能后向传播，这句话是否正确（  ）

		A. 正确的
		B. 错误的

正确答案：B

117.【单选】反向传播算法一开始计算什么内容的梯度，之后将其反向传播？（  ）

		A. 预测结果与样本标签之间的误差
		B. 各个输入样本的平方差之和
		C. 各个网络权重的平方差之和
		D. 以上都不对

正确答案：A

118.【单选】单层的神经网络反向传播算法也适用多层神经网络的反向传播，这句话正确吗？（  ）

		A. 正确
		B. 不正确

正确答案：B

119.【单选】一个完成的反向传播的步骤是（  ）

1 将隐藏层误差反向传播给输入层，调节隐藏层到输入层的权值和阈值

2 将输出层的误差反向传播给隐藏层，调整隐藏层到输出层的权值和阈值

3 将隐藏层的误差反向传播给隐藏层，调节隐藏层到隐藏层的权值和阈值

		A. 1 2 3
		B. 2 1 3
		C. 1 3 2
		D. 2 3 1

正确答案：D
